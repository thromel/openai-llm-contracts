{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Python with LLM Contract Language (LLMCL) Framework\n",
    "\n",
    "This notebook demonstrates the comprehensive features of the OpenAI Python SDK enhanced with the LLM Contract Language framework for building reliable, contract-based LLM applications.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction and Setup](#1-introduction-and-setup)\n",
    "2. [Basic OpenAI SDK Usage](#2-basic-openai-sdk-usage)\n",
    "3. [Contract-Based Validation](#3-contract-based-validation)\n",
    "4. [LLMCL (LLM Contract Language)](#4-llmcl-llm-contract-language)\n",
    "5. [Streaming with Contract Validation](#5-streaming-with-contract-validation)\n",
    "6. [Advanced Features](#6-advanced-features)\n",
    "7. [Performance Monitoring](#7-performance-monitoring)\n",
    "8. [Real-World Examples](#8-real-world-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Setup\n",
    "\n",
    "The LLM Design by Contract Framework provides:\n",
    "- **Contract-Based Validation**: Input and output validation using design-by-contract principles\n",
    "- **Multi-Provider Support**: Currently supports OpenAI with extensible architecture\n",
    "- **Comprehensive Contract Types**: 7 different contract categories\n",
    "- **Streaming Support**: Real-time validation for streaming responses\n",
    "- **Auto-Fix Suggestions**: Intelligent suggestions for contract violations\n",
    "- **LLMCL**: A domain-specific language for defining contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.1' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Installation (run once)\n",
    "!pip install -e .\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# OpenAI imports\n",
    "from openai import OpenAI\n",
    "\n",
    "# Contract framework imports\n",
    "from llm_contracts.providers.openai_provider import ImprovedOpenAIProvider\n",
    "from llm_contracts.contracts.base import (\n",
    "    PromptLengthContract,\n",
    "    PromptInjectionContract,\n",
    "    ContentPolicyContract,\n",
    "    JSONFormatContract,\n",
    "    ResponseTimeContract,\n",
    "    ConversationConsistencyContract,\n",
    "    MedicalDisclaimerContract\n",
    ")\n",
    "from llm_contracts.validators import InputValidator, OutputValidator\n",
    "from llm_contracts.core.exceptions import ContractViolationError\n",
    "\n",
    "# LLMCL imports\n",
    "from llm_contracts.language import LLMCLRuntime, ResolutionStrategy\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API key\n",
    "# Option 1: Set as environment variable\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Option 2: Pass directly (for demo purposes only)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", \"your-api-key-here\")\n",
    "\n",
    "if api_key == \"your-api-key-here\":\n",
    "    print(\"⚠️  Please set your OpenAI API key!\")\n",
    "else:\n",
    "    print(\"✅ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic OpenAI SDK Usage\n",
    "\n",
    "First, let's see how the standard OpenAI SDK works before adding contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard OpenAI client\n",
    "standard_client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Basic chat completion\n",
    "response = standard_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Standard OpenAI Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contract-Based Validation\n",
    "\n",
    "Now let's enhance the OpenAI client with contract-based validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an improved OpenAI provider with contract support\n",
    "provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "\n",
    "# Add input contracts\n",
    "provider.add_input_contract(PromptLengthContract(max_tokens=100))\n",
    "provider.add_input_contract(PromptInjectionContract())\n",
    "\n",
    "# Add output contracts\n",
    "provider.add_output_contract(JSONFormatContract())\n",
    "\n",
    "print(\"✅ Contract-enhanced provider created with input and output validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Valid request that passes all contracts\n",
    "try:\n",
    "    response = provider.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Always respond in valid JSON format.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Generate a user profile with name and age.\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"✅ Response passed all contracts:\")\n",
    "    print(response.choices[0].message.content)\n",
    "except ContractViolationError as e:\n",
    "    print(f\"❌ Contract violation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Input contract violation (prompt too long)\n",
    "try:\n",
    "    long_prompt = \"This is a very long prompt. \" * 50  # Exceeds token limit\n",
    "    response = provider.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": long_prompt}\n",
    "        ]\n",
    "    )\n",
    "except ContractViolationError as e:\n",
    "    print(f\"❌ Expected contract violation: {e}\")\n",
    "    print(f\"   Suggestion: {e.suggestion if hasattr(e, 'suggestion') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Different contract types\n",
    "# Create a provider with multiple contract types\n",
    "multi_contract_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "\n",
    "# Add various contract types\n",
    "contracts_demo = {\n",
    "    \"Input Contracts\": [\n",
    "        PromptLengthContract(max_tokens=200),\n",
    "        ContentPolicyContract(),\n",
    "        PromptInjectionContract()\n",
    "    ],\n",
    "    \"Output Contracts\": [\n",
    "        ResponseTimeContract(max_response_time=5.0),\n",
    "        ConversationConsistencyContract(),\n",
    "        MedicalDisclaimerContract()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add all contracts\n",
    "for contract_type, contracts in contracts_demo.items():\n",
    "    print(f\"\\nAdding {contract_type}:\")\n",
    "    for contract in contracts:\n",
    "        if \"Input\" in contract_type:\n",
    "            multi_contract_provider.add_input_contract(contract)\n",
    "        else:\n",
    "            multi_contract_provider.add_output_contract(contract)\n",
    "        print(f\"  - {contract.__class__.__name__}\")\n",
    "\n",
    "print(\"\\n✅ Multiple contracts configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLMCL (LLM Contract Language)\n",
    "\n",
    "LLMCL is a domain-specific language for defining contracts declaratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contracts using LLMCL syntax\n",
    "safety_contract = \"\"\"\n",
    "contract ChatbotSafety(priority = critical) {\n",
    "    # Input validation\n",
    "    require len(content) > 0 and len(content) < 4000\n",
    "        message: \"Input must be between 1 and 4000 characters\"\n",
    "    \n",
    "    require not match(content, \"(?i)(injection|exploit)\")\n",
    "        message: \"Potential security threat detected\"\n",
    "    \n",
    "    # Output validation\n",
    "    ensure not contains(response, \"password\")\n",
    "        message: \"Response contains sensitive information\"\n",
    "    \n",
    "    ensure len(response) > 10\n",
    "        message: \"Response too short\"\n",
    "        auto_fix: \"I'd be happy to help you. Could you please provide more details?\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "api_response_contract = \"\"\"\n",
    "contract APIResponse {\n",
    "    # Ensure valid JSON\n",
    "    ensure json_valid(response)\n",
    "        message: \"Response must be valid JSON\"\n",
    "        auto_fix: '{\"error\": \"Invalid response format\", \"original\": \"' + response + '\"}'\n",
    "    \n",
    "    # Ensure required fields\n",
    "    ensure contains(response, '\"status\"') and contains(response, '\"data\"')\n",
    "        message: \"Response must contain status and data fields\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "quality_contract = \"\"\"\n",
    "contract ConversationQuality(priority = high) {\n",
    "    # Ensure helpful responses\n",
    "    ensure len(response) > 50 or contains(response, \"?\")\n",
    "        message: \"Provide detailed responses or ask clarifying questions\"\n",
    "    \n",
    "    # Probabilistic quality check\n",
    "    ensure_prob not startswith(response, \"I don't know\"), 0.8\n",
    "        message: \"Should provide helpful answers at least 80% of the time\"\n",
    "        window_size: 50\n",
    "    \n",
    "    # Temporal constraint\n",
    "    temporal within 3 contains(response, \"help\") or contains(response, \"assist\")\n",
    "        message: \"Offer help within first 3 responses\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"✅ LLMCL contracts defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLMCL runtime\n",
    "runtime = LLMCLRuntime()\n",
    "\n",
    "# Load contracts asynchronously\n",
    "async def load_contracts():\n",
    "    print(\"📝 Loading LLMCL contracts...\")\n",
    "    \n",
    "    safety_name = await runtime.load_contract(safety_contract)\n",
    "    api_name = await runtime.load_contract(api_response_contract)\n",
    "    quality_name = await runtime.load_contract(quality_contract)\n",
    "    \n",
    "    print(f\"✅ Loaded contracts: {safety_name}, {api_name}, {quality_name}\")\n",
    "    return safety_name, api_name, quality_name\n",
    "\n",
    "# Run the async function\n",
    "safety_name, api_name, quality_name = await load_contracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create runtime context with conflict resolution\n",
    "context = runtime.create_context(\n",
    "    \"demo_session\",\n",
    "    conflict_strategy=ResolutionStrategy.MOST_RESTRICTIVE\n",
    ")\n",
    "\n",
    "# Add contracts to context\n",
    "runtime.add_contract_to_context(\"demo_session\", safety_name)\n",
    "runtime.add_contract_to_context(\"demo_session\", quality_name)\n",
    "\n",
    "print(\"✅ Runtime context created with contracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLMCL validation\n",
    "async def test_llmcl_validation():\n",
    "    print(\"🔍 Testing LLMCL Validation\\n\")\n",
    "    \n",
    "    # Test 1: Valid response\n",
    "    valid_response = \"This is a helpful and detailed response about Python programming. \" \\\n",
    "                    \"It provides useful information without any sensitive data.\"\n",
    "    \n",
    "    result = await runtime.validate(\n",
    "        valid_response,\n",
    "        \"demo_session\",\n",
    "        validation_type=\"output\",\n",
    "        additional_context={\"content\": \"Tell me about Python\"}\n",
    "    )\n",
    "    print(f\"1. Valid response: {result.is_valid}\")\n",
    "    \n",
    "    # Test 2: Too short response\n",
    "    short_response = \"OK\"\n",
    "    result = await runtime.validate(\n",
    "        short_response,\n",
    "        \"demo_session\",\n",
    "        validation_type=\"output\",\n",
    "        additional_context={\"content\": \"Explain quantum computing\"}\n",
    "    )\n",
    "    print(f\"\\n2. Short response: {result.is_valid}\")\n",
    "    if not result.is_valid:\n",
    "        print(f\"   Violation: {result.message}\")\n",
    "    \n",
    "    # Test 3: Security violation\n",
    "    security_violation = \"Your password is stored in the database\"\n",
    "    result = await runtime.validate(\n",
    "        security_violation,\n",
    "        \"demo_session\",\n",
    "        validation_type=\"output\",\n",
    "        additional_context={\"content\": \"How do I reset my password?\"}\n",
    "    )\n",
    "    print(f\"\\n3. Security violation: {result.is_valid}\")\n",
    "    if not result.is_valid:\n",
    "        print(f\"   Violation: {result.message}\")\n",
    "    \n",
    "    # Test 4: Auto-remediation\n",
    "    print(f\"\\n4. Auto-remediation test:\")\n",
    "    print(f\"   Original: {short_response}\")\n",
    "    fixed = await runtime.apply_auto_fix(short_response, \"demo_session\")\n",
    "    print(f\"   Fixed: {fixed}\")\n",
    "\n",
    "await test_llmcl_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test JSON API validation\n",
    "async def test_json_validation():\n",
    "    print(\"📊 Testing JSON API Validation\\n\")\n",
    "    \n",
    "    # Create API context\n",
    "    api_context = runtime.create_context(\"api_session\")\n",
    "    runtime.add_contract_to_context(\"api_session\", api_name)\n",
    "    \n",
    "    # Test 1: Valid JSON\n",
    "    valid_json = '{\"status\": \"success\", \"data\": {\"id\": 123, \"name\": \"test\"}}'\n",
    "    result = await runtime.validate(valid_json, \"api_session\")\n",
    "    print(f\"1. Valid JSON: {result.is_valid}\")\n",
    "    \n",
    "    # Test 2: Invalid JSON\n",
    "    invalid_json = \"This is not JSON\"\n",
    "    result = await runtime.validate(invalid_json, \"api_session\")\n",
    "    print(f\"\\n2. Invalid JSON: {result.is_valid}\")\n",
    "    if not result.is_valid:\n",
    "        print(f\"   Violation: {result.message}\")\n",
    "    \n",
    "    # Test 3: Apply auto-fix\n",
    "    fixed_json = await runtime.apply_auto_fix(invalid_json, \"api_session\")\n",
    "    print(f\"   Auto-fixed: {fixed_json}\")\n",
    "    \n",
    "    # Validate the fixed JSON\n",
    "    try:\n",
    "        parsed = json.loads(fixed_json)\n",
    "        print(f\"   ✅ Fixed JSON is valid: {json.dumps(parsed, indent=2)}\")\n",
    "    except:\n",
    "        print(f\"   ❌ Fixed JSON is still invalid\")\n",
    "\n",
    "await test_json_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Streaming with Contract Validation\n",
    "\n",
    "The framework supports real-time validation of streaming responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a provider for streaming\n",
    "stream_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "\n",
    "# Add contracts for streaming validation\n",
    "stream_provider.add_output_contract(JSONFormatContract())\n",
    "\n",
    "print(\"✅ Streaming provider configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Streaming response with validation\n",
    "print(\"🌊 Streaming Response with Contract Validation:\\n\")\n",
    "\n",
    "try:\n",
    "    stream = stream_provider.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Always respond in valid JSON format.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a JSON object with weather data including temperature, humidity, and conditions.\"}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Collect streamed chunks\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            full_response += content\n",
    "            print(content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n✅ Streaming completed successfully!\")\n",
    "    \n",
    "    # Validate the complete response\n",
    "    try:\n",
    "        parsed = json.loads(full_response)\n",
    "        print(\"✅ Response is valid JSON:\")\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "    except:\n",
    "        print(\"❌ Response is not valid JSON\")\n",
    "        \n",
    "except ContractViolationError as e:\n",
    "    print(f\"\\n❌ Contract violation during streaming: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Features\n",
    "\n",
    "Let's explore some advanced features of the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: Circuit Breaker Pattern\n",
    "# The framework includes a circuit breaker to prevent cascade failures\n",
    "\n",
    "advanced_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "advanced_provider.add_output_contract(JSONFormatContract())\n",
    "\n",
    "# The circuit breaker activates after repeated contract failures\n",
    "print(\"🔌 Circuit Breaker Pattern:\")\n",
    "print(\"- Monitors contract validation failures\")\n",
    "print(\"- Opens circuit after threshold (default: 5 failures)\")\n",
    "print(\"- Allows degraded operation without validation\")\n",
    "print(\"- Auto-resets after timeout period\")\n",
    "\n",
    "# You can manually reset if needed\n",
    "advanced_provider.reset_circuit_breaker()\n",
    "print(\"\\n✅ Circuit breaker reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Async Support\n",
    "async def async_example():\n",
    "    \"\"\"Example of async API calls with contracts.\"\"\"\n",
    "    print(\"⚡ Async API Call Example:\\n\")\n",
    "    \n",
    "    # Async provider works the same way\n",
    "    async_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "    async_provider.add_input_contract(PromptLengthContract(max_tokens=150))\n",
    "    async_provider.add_output_contract(JSONFormatContract())\n",
    "    \n",
    "    # Make async call\n",
    "    response = await async_provider.chat.completions.acreate(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Always respond in JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a JSON object with book information.\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    print(f\"Response: {content}\")\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(content)\n",
    "        print(\"\\n✅ Valid JSON response:\")\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "    except:\n",
    "        print(\"\\n❌ Invalid JSON response\")\n",
    "\n",
    "# Run async example\n",
    "await async_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Custom Contract Creation\n",
    "from llm_contracts.contracts.base import BaseContract\n",
    "from llm_contracts.core.interfaces import ValidationResult\n",
    "\n",
    "class CustomWordCountContract(BaseContract):\n",
    "    \"\"\"Custom contract to ensure response has specific word count.\"\"\"\n",
    "    \n",
    "    def __init__(self, min_words: int = 10, max_words: int = 100):\n",
    "        super().__init__()\n",
    "        self.name = \"WordCountContract\"\n",
    "        self.min_words = min_words\n",
    "        self.max_words = max_words\n",
    "    \n",
    "    def validate(self, content: str) -> ValidationResult:\n",
    "        \"\"\"Validate word count in response.\"\"\"\n",
    "        word_count = len(content.split())\n",
    "        \n",
    "        if word_count < self.min_words:\n",
    "            return ValidationResult(\n",
    "                is_valid=False,\n",
    "                message=f\"Response too short: {word_count} words (minimum: {self.min_words})\",\n",
    "                auto_fix_suggestion=\"Please provide a more detailed response with additional information.\"\n",
    "            )\n",
    "        \n",
    "        if word_count > self.max_words:\n",
    "            return ValidationResult(\n",
    "                is_valid=False,\n",
    "                message=f\"Response too long: {word_count} words (maximum: {self.max_words})\",\n",
    "                auto_fix_suggestion=\"Please provide a more concise response.\"\n",
    "            )\n",
    "        \n",
    "        return ValidationResult(is_valid=True)\n",
    "\n",
    "# Use custom contract\n",
    "custom_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "custom_provider.add_output_contract(CustomWordCountContract(min_words=20, max_words=50))\n",
    "\n",
    "print(\"✅ Custom contract created and added to provider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test custom contract\n",
    "try:\n",
    "    response = custom_provider.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Explain quantum computing in exactly 30 words.\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    word_count = len(content.split())\n",
    "    \n",
    "    print(f\"Response ({word_count} words):\")\n",
    "    print(content)\n",
    "    print(\"\\n✅ Response passed word count validation!\")\n",
    "    \n",
    "except ContractViolationError as e:\n",
    "    print(f\"❌ Contract violation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Monitoring\n",
    "\n",
    "The framework includes comprehensive metrics and performance monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a provider and make some calls to generate metrics\n",
    "metrics_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "metrics_provider.add_input_contract(PromptLengthContract(max_tokens=100))\n",
    "metrics_provider.add_output_contract(JSONFormatContract())\n",
    "\n",
    "print(\"📊 Generating performance metrics...\\n\")\n",
    "\n",
    "# Make several calls to generate metrics\n",
    "for i in range(3):\n",
    "    try:\n",
    "        response = metrics_provider.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Always respond in JSON format.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Generate a JSON object with data for item {i+1}\"}\n",
    "            ],\n",
    "            max_tokens=100\n",
    "        )\n",
    "        print(f\"✅ Request {i+1} successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Request {i+1} failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display metrics\n",
    "metrics = metrics_provider.get_metrics()\n",
    "\n",
    "print(\"📈 Performance Metrics Report:\\n\")\n",
    "\n",
    "print(f\"Total Validations: {metrics['total_validations']}\")\n",
    "print(f\"Violation Rate: {metrics['violation_rate']:.2%}\")\n",
    "\n",
    "print(\"\\nSlowest Contracts:\")\n",
    "for contract in metrics.get('slowest_contracts', []):\n",
    "    print(f\"  - {contract['name']}: {contract['avg_latency']:.3f}s avg\")\n",
    "\n",
    "print(\"\\nMost Violated Contracts:\")\n",
    "for contract in metrics.get('most_violated_contracts', []):\n",
    "    print(f\"  - {contract['name']}: {contract['violations']} violations\")\n",
    "\n",
    "print(\"\\nAuto-Fix Success Rates:\")\n",
    "for contract_name, stats in metrics.get('auto_fix_success_rates', {}).items():\n",
    "    if stats['total'] > 0:\n",
    "        success_rate = stats['success'] / stats['total'] * 100\n",
    "        print(f\"  - {contract_name}: {success_rate:.1f}% ({stats['success']}/{stats['total']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMCL Runtime Metrics\n",
    "print(\"\\n📊 LLMCL Runtime Metrics:\\n\")\n",
    "\n",
    "global_metrics = runtime.get_global_metrics()\n",
    "for key, value in global_metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nSession Statistics:\")\n",
    "stats = runtime.get_context_statistics(\"demo_session\")\n",
    "print(f\"Total validations: {stats['total_validations']}\")\n",
    "print(f\"Total violations: {stats['total_violations']}\")\n",
    "print(f\"Auto-fixes applied: {stats['total_auto_fixes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-World Examples\n",
    "\n",
    "Let's explore some practical use cases for the contract framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: API Response Generation with Strict Schema\n",
    "print(\"🌐 Example 1: API Response Generation\\n\")\n",
    "\n",
    "# Define a strict JSON schema\n",
    "api_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"status\": {\"type\": \"string\", \"enum\": [\"success\", \"error\"]},\n",
    "        \"data\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"id\": {\"type\": \"integer\"},\n",
    "                \"name\": {\"type\": \"string\"},\n",
    "                \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
    "                \"created_at\": {\"type\": \"string\", \"format\": \"date-time\"}\n",
    "            },\n",
    "            \"required\": [\"id\", \"name\", \"email\"]\n",
    "        },\n",
    "        \"message\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"status\", \"data\"]\n",
    "}\n",
    "\n",
    "# Create provider with schema validation\n",
    "api_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "api_provider.add_output_contract(JSONFormatContract(schema=api_schema))\n",
    "\n",
    "try:\n",
    "    response = api_provider.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an API that returns user data in JSON format.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Get user with ID 123\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    data = json.loads(content)\n",
    "    \n",
    "    print(\"✅ Valid API Response:\")\n",
    "    print(json.dumps(data, indent=2))\n",
    "    \n",
    "except ContractViolationError as e:\n",
    "    print(f\"❌ Schema validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Content Moderation Pipeline\n",
    "print(\"🛡️ Example 2: Content Moderation Pipeline\\n\")\n",
    "\n",
    "# LLMCL contract for content moderation\n",
    "moderation_contract = \"\"\"\n",
    "contract ContentModeration(priority = critical) {\n",
    "    # Input checks\n",
    "    require not match(content, \"(?i)(hate|violence|harassment)\")\n",
    "        message: \"Inappropriate content detected in input\"\n",
    "    \n",
    "    # Output checks\n",
    "    ensure not contains(response, \"offensive\")\n",
    "        message: \"Response contains inappropriate content\"\n",
    "    \n",
    "    ensure contains(response, \"respectful\") or contains(response, \"appropriate\")\n",
    "        message: \"Response should emphasize respectful communication\"\n",
    "        auto_fix: \"I appreciate your question. Let me provide a respectful and appropriate response.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Load and test moderation contract\n",
    "async def test_moderation():\n",
    "    mod_name = await runtime.load_contract(moderation_contract)\n",
    "    mod_context = runtime.create_context(\"moderation_session\")\n",
    "    runtime.add_contract_to_context(\"moderation_session\", mod_name)\n",
    "    \n",
    "    # Test appropriate content\n",
    "    appropriate = \"How can I help my community?\"\n",
    "    result = await runtime.validate(\n",
    "        appropriate,\n",
    "        \"moderation_session\",\n",
    "        validation_type=\"input\",\n",
    "        additional_context={\"content\": appropriate}\n",
    "    )\n",
    "    print(f\"✅ Appropriate content: {result.is_valid}\")\n",
    "    \n",
    "    # Test inappropriate content\n",
    "    inappropriate = \"I hate this service\"\n",
    "    result = await runtime.validate(\n",
    "        inappropriate,\n",
    "        \"moderation_session\",\n",
    "        validation_type=\"input\",\n",
    "        additional_context={\"content\": inappropriate}\n",
    "    )\n",
    "    print(f\"\\n❌ Inappropriate content: {result.is_valid}\")\n",
    "    if not result.is_valid:\n",
    "        print(f\"   Reason: {result.message}\")\n",
    "\n",
    "await test_moderation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Multi-turn Conversation with State Tracking\n",
    "print(\"💬 Example 3: Multi-turn Conversation Management\\n\")\n",
    "\n",
    "# LLMCL contract for conversation management\n",
    "conversation_contract = \"\"\"\n",
    "contract ConversationManagement {\n",
    "    # Track conversation state\n",
    "    state user_name: string = \"\"\n",
    "    state topic: string = \"\"\n",
    "    state turn_count: int = 0\n",
    "    \n",
    "    # Temporal constraints\n",
    "    temporal within 3 extract(response, \"name\") -> user_name\n",
    "        message: \"Should ask for user's name within first 3 turns\"\n",
    "    \n",
    "    # Consistency checks\n",
    "    ensure turn_count > 3 implies len(user_name) > 0\n",
    "        message: \"Should have user's name by turn 4\"\n",
    "    \n",
    "    # Quality metrics\n",
    "    ensure_prob contains(response, user_name) when len(user_name) > 0, 0.7\n",
    "        message: \"Should use user's name in 70% of responses\"\n",
    "        window_size: 10\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create conversation provider\n",
    "conv_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "conv_provider.add_output_contract(ConversationConsistencyContract())\n",
    "\n",
    "print(\"Starting multi-turn conversation...\\n\")\n",
    "\n",
    "# Simulate conversation\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Start by greeting the user and asking their name.\"}\n",
    "]\n",
    "\n",
    "# Turn 1\n",
    "response = conv_provider.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")\n",
    "assistant_message = response.choices[0].message.content\n",
    "print(f\"Assistant: {assistant_message}\")\n",
    "messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "# Turn 2 - User provides name\n",
    "user_message = \"Hi! My name is Alice.\"\n",
    "print(f\"\\nUser: {user_message}\")\n",
    "messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "response = conv_provider.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=100\n",
    ")\n",
    "assistant_message = response.choices[0].message.content\n",
    "print(f\"Assistant: {assistant_message}\")\n",
    "\n",
    "print(\"\\n✅ Multi-turn conversation with consistency tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Medical/Legal Disclaimer Enforcement\n",
    "print(\"⚕️ Example 4: Medical Disclaimer Enforcement\\n\")\n",
    "\n",
    "# Create provider with medical disclaimer contract\n",
    "medical_provider = ImprovedOpenAIProvider(api_key=api_key)\n",
    "medical_provider.add_output_contract(MedicalDisclaimerContract())\n",
    "\n",
    "try:\n",
    "    response = medical_provider.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"I have a headache. What medication should I take?\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    print(\"Response with medical disclaimer:\")\n",
    "    print(content)\n",
    "    \n",
    "    # Check if disclaimer is present\n",
    "    disclaimer_keywords = [\"medical advice\", \"healthcare professional\", \"doctor\", \"physician\"]\n",
    "    has_disclaimer = any(keyword in content.lower() for keyword in disclaimer_keywords)\n",
    "    \n",
    "    if has_disclaimer:\n",
    "        print(\"\\n✅ Medical disclaimer properly included\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Medical disclaimer may be missing\")\n",
    "        \n",
    "except ContractViolationError as e:\n",
    "    print(f\"❌ Contract violation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key features of the OpenAI Python SDK with LLM Contract Language framework:\n",
    "\n",
    "### Key Features Covered:\n",
    "1. **Contract-Based Validation**: Input and output validation with multiple contract types\n",
    "2. **LLMCL**: Domain-specific language for defining contracts declaratively\n",
    "3. **Streaming Support**: Real-time validation of streaming responses\n",
    "4. **Auto-Remediation**: Automatic fixing of contract violations\n",
    "5. **Performance Monitoring**: Comprehensive metrics and health reporting\n",
    "6. **Circuit Breaker**: Fault tolerance for production environments\n",
    "7. **Async Support**: Full async/await compatibility\n",
    "8. **Custom Contracts**: Extensible framework for custom validation logic\n",
    "\n",
    "### Benefits:\n",
    "- **Reliability**: Ensure LLM outputs meet specific requirements\n",
    "- **Security**: Detect and prevent prompt injection attacks\n",
    "- **Compliance**: Enforce content policies and legal requirements\n",
    "- **Performance**: Monitor and optimize contract validation\n",
    "- **Developer Experience**: Drop-in replacement for OpenAI SDK\n",
    "\n",
    "### Next Steps:\n",
    "1. Explore more contract types in `llm_contracts/contracts/base.py`\n",
    "2. Create custom contracts for your specific use cases\n",
    "3. Integrate with your production applications\n",
    "4. Monitor metrics and optimize performance\n",
    "5. Contribute to the open-source project\n",
    "\n",
    "For more information, see the documentation in the `docs/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
